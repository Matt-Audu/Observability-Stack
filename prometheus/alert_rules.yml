groups:
- name: Infrastructure Alerts
  rules:
  # High CPU Usage
  - alert: HighCPUUsage
    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage on {{ $labels.instance }}"
      description: "CPU usage on {{ $labels.instance }} is at {{ printf \"%.2f\" $value }}% for more than 5 minutes."

  # Critical CPU Usage
  - alert: CriticalCPUUsage
    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 95
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "Critical CPU usage on {{ $labels.instance }}"
      description: "CPU usage on {{ $labels.instance }} is at {{ printf \"%.2f\" $value }}% for more than 2 minutes."

  # High Memory Usage
  - alert: HighMemoryUsage
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage on {{ $labels.instance }}"
      description: "Memory usage on {{ $labels.instance }} is at {{ printf \"%.2f\" $value }}%."

  # Critical Memory Usage
  - alert: CriticalMemoryUsage
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 95
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "Critical memory usage on {{ $labels.instance }}"
      description: "Memory usage on {{ $labels.instance }} is at {{ printf \"%.2f\" $value }}%."

  # High Disk Usage
  - alert: HighDiskUsage
    expr: (1 - (node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.lxcfs"} / node_filesystem_size_bytes{fstype!~"tmpfs|fuse.lxcfs"})) * 100 > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High disk usage on {{ $labels.instance }}"
      description: "Disk usage on filesystem {{ $labels.mountpoint }} ({{ $labels.instance }}) is at {{ printf \"%.2f\" $value }}%."

  # Critical Disk Usage
  - alert: CriticalDiskUsage
    expr: (1 - (node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.lxcfs"} / node_filesystem_size_bytes{fstype!~"tmpfs|fuse.lxcfs"})) * 100 > 90
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "Critical disk usage on {{ $labels.instance }}"
      description: "Disk usage on filesystem {{ $labels.mountpoint }} ({{ $labels.instance }}) is at {{ printf \"%.2f\" $value }}%."

  # Instance Down
  - alert: InstanceDown
    expr: up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Instance {{ $labels.instance }} is down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 1 minute."

  # High Load Average
  - alert: HighLoadAverage
    expr: node_load1 / count(node_cpu_seconds_total{mode="idle"}) by (instance) > 1.5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High load average on {{ $labels.instance }}"
      description: "Load average (1 min) on {{ $labels.instance }} is {{ printf \"%.2f\" $value }}, which is high for the available CPU cores."

- name: applications
  rules:
  # High HTTP Error Rate
  - alert: HighHTTPErrorRate
    expr: sum(rate(http_requests_total{status=~"5.."}[5m])) by (job, instance) / sum(rate(http_requests_total[5m])) by (job, instance) * 100 > 5
    for: 3m
    labels:
      severity: warning
    annotations:
      summary: "High HTTP 5xx error rate for {{ $labels.job }}"
      description: "The HTTP 5xx error rate for job {{ $labels.job }} on {{ $labels.instance }} is {{ printf \"%.2f\" $value }}%."

  # Critical HTTP Error Rate
  - alert: CriticalHTTPErrorRate
    expr: sum(rate(http_requests_total{status=~"5.."}[5m])) by (job, instance) / sum(rate(http_requests_total[5m])) by (job, instance) * 100 > 10
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Critical HTTP 5xx error rate for {{ $labels.job }}"
      description: "The HTTP 5xx error rate for job {{ $labels.job }} on {{ $labels.instance }} is {{ printf \"%.2f\" $value }}%."

  # High Response Time
  - alert: HighResponseTime
    expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, job)) > 0.5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High response time for {{ $labels.job }}"
      description: "The 95th percentile response time for job {{ $labels.job }} is {{ printf \"%.2f\" $value }}s."

- name: database
  rules:
  # Database Down
  - alert: PostgreSQLDown
    expr: pg_up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "PostgreSQL is down"
      description: "PostgreSQL database on instance {{ $labels.instance }} is not responding."

- name: containers
  rules:
  # Container Down
  - alert: ContainerDown
    # The 'absent(container_last_seen)' expression is often too broad.
    # A better approach is to check if a container tracked by cAdvisor is not running.
    expr: time() - container_last_seen > 300
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Container {{ $labels.name }} is down"
      description: "Container {{ $labels.name }} (image: {{ $labels.image }}) has not been seen for more than 5 minutes."

  # High Container CPU
  - alert: HighContainerCPU
    expr: sum(rate(container_cpu_usage_seconds_total[5m])) by (name, image) * 100 > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage in container {{ $labels.name }}"
      description: "Container {{ $labels.name }} (image: {{ $labels.image }}) CPU usage is at {{ printf \"%.2f\" $value }}%."

  # High Container Memory
  - alert: HighContainerMemory
    expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage in container {{ $labels.name }}"
      description: "Container {{ $labels.name }} (image: {{ $labels.image }}) memory usage is at {{ printf \"%.2f\" $value }}%."

- name: alertmanager
  rules:
  - alert: AlertmanagerDown
    expr: up{job="alertmanager"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Alertmanager is down"
      description: "The Alertmanager instance {{ $labels.instance }} is not responding."

  # High Failed Notifications
  - alert: AlertmanagerFailedNotifications
    expr: rate(alertmanager_notifications_failed_total[5m]) > 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Alertmanager failed notifications"
      description: "Alertmanager on {{ $labels.instance }} is failing to send {{ printf \"%.2f\" $value }} notifications per second."

- name: prometheus
  rules:
  # Prometheus Target Down - This is a duplicate of InstanceDown. A better rule is to check for scrape health.
  - alert: PrometheusTargetScrapeFailed
    expr: up == 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Prometheus target scrape failed"
      description: "Prometheus failed to scrape the target {{ $labels.instance }} of job {{ $labels.job }}."

  # Prometheus Config Reload Failed
  - alert: PrometheusConfigReloadFailed
    expr: prometheus_config_last_reload_successful != 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Prometheus configuration reload failed"
      description: "Prometheus on {{ $labels.instance }} failed to reload its configuration."

  # Prometheus TSDB Compaction Failed
  - alert: PrometheusTSDBCompactionsFailed
    expr: increase(prometheus_tsdb_compactions_failed_total[3h]) > 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Prometheus TSDB compactions failed"
      description: "Prometheus on {{ $labels.instance }} has encountered {{ $value }} TSDB compaction failures in the last 3 hours."

  # SSL Certificate Expired
  - alert: SSLCertificateExpired
    expr: probe_ssl_earliest_cert_expiry - time() <= 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "SSL certificate has expired"
      description: "The SSL certificate for instance {{ $labels.instance }} has expired."